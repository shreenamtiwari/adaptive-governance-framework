# Adaptive Data Governance Framework for E-Commerce

An intelligent, policy-driven data governance framework built with **PySpark**, **Delta Lake**, and **Apache Airflow** â€” designed for e-commerce data platforms that demand robust data quality, PII protection, and lineage tracking at scale.

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Setup Instructions](#setup-instructions)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---

## Overview

This framework provides an end-to-end adaptive data governance solution for e-commerce platforms. It implements a **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) with built-in:

- **Data Quality Enforcement** â€” Schema validation, anomaly detection, and quarantine workflows
- **PII Detection & Masking** â€” Automated scanning and tokenization of personally identifiable information
- **Policy-as-Code Governance** â€” Declarative governance rules that adapt based on data profiling results
- **Data Lineage Tracking** â€” Full traceability from raw ingestion through to curated gold-layer datasets
- **Orchestration** â€” Apache Airflow DAGs for scheduling and monitoring governance pipelines

### Key Technologies

| Component          | Technology                  |
|--------------------|-----------------------------| 
| Processing Engine  | Apache PySpark              |
| Storage Layer      | Delta Lake                  |
| Orchestration      | Apache Airflow              |
| Cloud Platform     | Google Cloud Platform (GCP) |
| Language           | Python 3.10+                |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Apache Airflow (Orchestration)               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Ingest   â”‚â”€â”€â”€â–¶â”‚ Quality  â”‚â”€â”€â”€â–¶â”‚ PII      â”‚â”€â”€â”€â–¶â”‚ Govern   â”‚    â”‚
â”‚   â”‚ DAG      â”‚    â”‚ DAG      â”‚    â”‚ Scan DAG â”‚    â”‚ DAG      â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data  â”‚   â”‚ Bronze Layer â”‚  â”‚  Silver   â”‚  â”‚   Gold Layer   â”‚
â”‚  (Landing) â”‚â”€â”€â–¶â”‚ (Delta Lake) â”‚â”€â–¶â”‚  Layer    â”‚â”€â–¶â”‚  (Delta Lake)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                                   â”‚ Quarantine â”‚
                                   â”‚  (Failed)  â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Cross-Cutting Concerns                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Lineage   â”‚  â”‚  PII         â”‚  â”‚  Adaptive Policy Engine   â”‚  â”‚
â”‚  â”‚  Tracking  â”‚  â”‚  Detection   â”‚  â”‚  (Policy-as-Code)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **TODO:** Replace with a detailed architecture diagram (e.g., draw.io, Lucidchart, or Mermaid export).

---

## Project Structure

```
adaptive-governance-framework/
â”œâ”€â”€ .gitignore                  # Ignore rules for Python, PySpark, data, Airflow, secrets
â”œâ”€â”€ .env.example                # Environment variable template
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                 # Raw ingested data (append-only Delta tables)
â”‚   â”œâ”€â”€ silver/                 # Cleaned, validated, and deduplicated data
â”‚   â”œâ”€â”€ gold/                   # Business-level aggregations and curated datasets
â”‚   â”œâ”€â”€ raw/                    # Landing zone for source system extracts
â”‚   â””â”€â”€ quarantine/             # Records that failed quality or governance checks
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # Data ingestion modules (batch & streaming)
â”‚   â”œâ”€â”€ quality/                # Data quality rules, validators, and profilers
â”‚   â”œâ”€â”€ governance/             # Policy engine, lineage, and access control
â”‚   â”œâ”€â”€ pii_detection/          # PII scanning, classification, and masking
â”‚   â””â”€â”€ utils/                  # Shared utilities, logging, and Spark session helpers
â”œâ”€â”€ tests/                      # Unit and integration tests
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                   # Airflow DAG definitions
â”‚   â”œâ”€â”€ logs/                   # Airflow execution logs
â”‚   â””â”€â”€ plugins/                # Custom Airflow operators and hooks
â”œâ”€â”€ config/                     # YAML/JSON configuration files for policies and schemas
â”œâ”€â”€ docs/                       # Documentation, ADRs, and design specs
â”œâ”€â”€ models/                     # Trained ML models (e.g., PII classifiers)
â””â”€â”€ notebooks/                  # Jupyter/Databricks notebooks for exploration
```

---

## Prerequisites

- **Python** 3.10 or higher
- **Apache Spark** 3.4+ with PySpark
- **Delta Lake** 2.4+
- **Apache Airflow** 2.7+
- **Google Cloud SDK** (for GCP integration)
- **Docker & Docker Compose** (recommended for local Airflow)

---

## Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/KartikayRaniwala/adaptive-governance-framework.git
cd adaptive-governance-framework
```

### 2. Create a Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Configure Environment Variables

```bash
cp .env.example .env
# Edit .env with your actual credentials and configuration
```

### 5. Initialize Airflow

```bash
export AIRFLOW_HOME=$(pwd)/airflow
airflow db init
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

### 6. Run Tests

```bash
pytest tests/ -v --tb=short
```

### 7. Start the Framework

```bash
# Start Airflow (in separate terminals)
airflow webserver --port 8080
airflow scheduler

# Or use Docker Compose
docker-compose up -d
```

---

## Usage

### Running a Governance Pipeline

```python
from src.ingestion.batch_ingester import BatchIngester
from src.quality.validator import DataQualityValidator
from src.pii_detection.scanner import PIIScanner
from src.governance.policy_engine import PolicyEngine

# Initialize components
ingester = BatchIngester(source="gcs://ecommerce-raw/orders/")
validator = DataQualityValidator(config="config/quality_rules.yaml")
scanner = PIIScanner(config="config/pii_policies.yaml")
engine = PolicyEngine(config="config/governance_policies.yaml")

# Execute pipeline
raw_df = ingester.ingest()
validated_df, quarantined_df = validator.validate(raw_df)
masked_df = scanner.scan_and_mask(validated_df)
engine.apply_policies(masked_df)
```

---

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit your changes (`git commit -m 'Add your feature'`)
4. Push to the branch (`git push origin feature/your-feature`)
5. Open a Pull Request

---

## License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.